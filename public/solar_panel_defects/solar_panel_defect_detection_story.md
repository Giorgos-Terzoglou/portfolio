# Solar Panel Defect Detection Using UAV RGB & Thermal Imagery

## Overview
This project presents an end-to-end computer vision system for detecting and classifying defects in photovoltaic panels using drone-acquired RGB and thermal imagery. The system was developed and evaluated on real-world data and published as a peer-reviewed IEEE paper. The primary objective was to replace manual inspection with an automated, scalable, and reliable inspection pipeline suitable for large solar parks.

---

## System Architecture
**UAV Image Acquisition → Panel Detection → Panel Segmentation → Fault Classification & Thermal Analysis → Fault Visualization**

The system is designed as a modular pipeline where each stage refines the information passed to the next, prioritizing robustness and interpretability over purely end-to-end black-box modeling.

---

## Core Pipeline Stages

### 1. Panel Detection (YOLOv5)
- RGB images are captured by UAVs under real operational conditions.
- A YOLOv5-based object detector identifies individual solar panels.
- Trained on a manually annotated dataset (>300 panels).
- Achieved ~90% detection confidence on test images, including background panels.

**Purpose:** isolate candidate panels reliably before further analysis.

---

### 2. Panel Segmentation (UNet + Classical CV Fallback)
- Detected panels often include background noise that degrades classification.
- A UNet-based segmentation model isolates the interior of each panel.
- Achieved ~85% pixel-level accuracy.
- When segmentation fails, a classical CV fallback is applied:
  - Canny edge detection
  - Hough line detection
  - Line extension and contour extraction
  - Perspective warping to standard panel shape

**Key insight:** combining deep learning with classical CV significantly improves robustness.

---

### 3. Fault Classification (EfficientNet)
- Panels are classified as:
  - No fault
  - Cell fault
  - Diode fault
  - Multi-cell fault
  - Multi-diode fault
- Due to limited real faulty samples, a synthetic dataset was generated by injecting realistic anomalies.
- EfficientNet selected after extensive architecture comparison.
- Achieved ~95% classification accuracy on test data.
- Grad-CAM heatmaps used to visualize decision-critical regions.

**Focus:** accuracy, generalization, and explainability.

---

### 4. Thermal Statistics Analysis
- Thermal data is analyzed using statistical descriptors:
  - min, max, mean, median
  - standard deviation
  - skewness and kurtosis
- Used to:
  - validate classifier predictions
  - detect offline or subtle faults missed by classification
- A Random Forest model achieved ~95.7% accuracy on fault/no-fault detection.

**Result:** complementary safety layer beyond image classification.

---

## Key Technical Challenges
- Limited availability of real faulty panel data.
- High visual similarity between fault types.
- Ensuring segmentation accuracy under varying perspectives.
- Designing a system that generalizes across different solar parks.

---

## Limitations
- Synthetic data used for fault augmentation.
- UAV image quality dependent on flight conditions.
- Not designed for real-time onboard inference.
- Requires calibrated RGB–thermal alignment.

---

## Key Takeaway
This project demonstrates my ability to design **production-oriented computer vision pipelines** that combine deep learning, classical computer vision, explainability, and statistical validation. It emphasizes system robustness, interpretability, and real-world applicability rather than isolated model performance.
